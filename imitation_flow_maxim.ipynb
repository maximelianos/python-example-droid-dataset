{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imitation Minimal Viable Example\n",
    "\n",
    "This notebook tests an imitation system using other demonstrations as pseudo live views.\n",
    "\n",
    "1. This uses optical flow for tracking correspondence.\n",
    "2. It just tracks one center keypoint.\n",
    "\n",
    "\n",
    "## Load Recorded Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "\n",
    "import ipywidgets\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import casino\n",
    "#from DITTO.data import Hands23Dataset, get_all_runs\n",
    "#from DITTO.config import BASE_RECORDING_PATH, TIME_STEPS\n",
    "# from DITTO.tracking_3D import Step3DMethod\n",
    "\n",
    "\n",
    "# Activate the interactive stuff\n",
    "# https://github.com/microsoft/vscode-jupyter/wiki/Using-%25matplotlib-widget-instead-of-%25matplotlib-notebook,tk,etc\n",
    "import ipympl\n",
    "%matplotlib widget\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_all_runs' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m PLOT_3D_TRAJECTORIES \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      5\u001b[0m session_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoke_tray\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m all_runs \u001b[38;5;241m=\u001b[39m \u001b[43mget_all_runs\u001b[49m(only_keywords\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mstr\u001b[39m(session_id)])\n\u001b[1;32m      8\u001b[0m loaders: List[Hands23Dataset] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m tqdm(all_runs, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_all_runs' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Notebook settings - DON'T USE\n",
    "PLOT_2D_TRAJECTORIES = False\n",
    "PLOT_3D_TRAJECTORIES = True\n",
    "\n",
    "session_id = \"coke_tray\"\n",
    "all_runs = get_all_runs(only_keywords=[str(session_id)])\n",
    "\n",
    "loaders: List[Hands23Dataset] = []\n",
    "for ep in tqdm(all_runs, desc=\"Loading\"):\n",
    "    loaders.append(Hands23Dataset(session_id / ep, lazy_loading=True))\n",
    "\n",
    "# loaders: List[Hands23Dataset] = [\n",
    "#    Hands23Dataset(session_id / \"000\"),\n",
    "#    Hands23Dataset(session_id / \"001\")\n",
    "# Hands23Dataset(session_id / \"004\") # Demo --> Live pose estimation is not optimal\n",
    "# Hands23Dataset(session_id / \"001\") # Demo --> Live pose estimation is not optimal\n",
    "# ]\n",
    "\n",
    "print(f\"Total runs {len(loaders)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode sec 10\n",
      "frames 152\n",
      "fps 14.20\n",
      "frame 1\n",
      "gripper closed False\n",
      "frame 2\n",
      "gripper closed False\n",
      "frame 3\n",
      "gripper closed False\n",
      "frame 4\n",
      "gripper closed False\n",
      "frame 5\n",
      "gripper closed False\n",
      "frame 6\n",
      "gripper closed False\n",
      "frame 7\n",
      "gripper closed False\n",
      "frame 8\n",
      "gripper closed False\n",
      "frame 9\n",
      "gripper closed False\n",
      "frame 10\n",
      "gripper closed False\n",
      "frame 11\n",
      "gripper closed False\n",
      "frame 12\n",
      "gripper closed False\n",
      "frame 13\n",
      "gripper closed False\n",
      "frame 14\n",
      "gripper closed False\n",
      "frame 15\n",
      "gripper closed False\n",
      "frame 16\n",
      "gripper closed False\n",
      "frame 17\n",
      "gripper closed False\n",
      "frame 18\n",
      "gripper closed False\n",
      "frame 19\n",
      "gripper closed False\n",
      "frame 20\n",
      "gripper closed False\n",
      "frame 21\n",
      "gripper closed False\n",
      "frame 22\n",
      "gripper closed False\n",
      "frame 23\n",
      "gripper closed False\n",
      "frame 24\n",
      "gripper closed False\n",
      "frame 25\n",
      "gripper closed False\n",
      "frame 26\n",
      "gripper closed False\n",
      "frame 27\n",
      "gripper closed False\n",
      "frame 28\n",
      "gripper closed False\n",
      "frame 29\n",
      "gripper closed False\n",
      "frame 30\n",
      "gripper closed False\n",
      "frame 31\n",
      "gripper closed False\n",
      "frame 32\n",
      "gripper closed False\n",
      "frame 33\n",
      "gripper closed False\n",
      "frame 34\n",
      "gripper closed False\n",
      "frame 35\n",
      "gripper closed False\n",
      "frame 36\n",
      "gripper closed False\n",
      "frame 37\n",
      "gripper closed False\n",
      "frame 38\n",
      "gripper closed False\n",
      "frame 39\n",
      "gripper closed False\n",
      "frame 40\n",
      "gripper closed False\n",
      "frame 41\n",
      "gripper closed False\n",
      "frame 42\n",
      "gripper closed False\n",
      "frame 43\n",
      "gripper closed False\n",
      "frame 44\n",
      "gripper closed True\n",
      "frame 45\n",
      "gripper closed True\n",
      "frame 46\n",
      "gripper closed True\n",
      "frame 47\n",
      "gripper closed True\n",
      "frame 48\n",
      "gripper closed True\n",
      "frame 49\n",
      "gripper closed True\n",
      "frame 50\n",
      "gripper closed True\n",
      "frame 51\n",
      "gripper closed True\n",
      "frame 52\n",
      "gripper closed True\n",
      "frame 53\n",
      "gripper closed True\n",
      "frame 54\n",
      "gripper closed True\n",
      "frame 55\n",
      "gripper closed True\n",
      "frame 56\n",
      "gripper closed True\n",
      "frame 57\n",
      "gripper closed True\n",
      "frame 58\n",
      "gripper closed True\n",
      "frame 59\n",
      "gripper closed True\n",
      "frame 60\n",
      "gripper closed True\n",
      "frame 61\n",
      "gripper closed True\n",
      "frame 62\n",
      "gripper closed True\n",
      "frame 63\n",
      "gripper closed True\n",
      "frame 64\n",
      "gripper closed True\n",
      "frame 65\n",
      "gripper closed True\n",
      "frame 66\n",
      "gripper closed True\n",
      "frame 67\n",
      "gripper closed True\n",
      "frame 68\n",
      "gripper closed True\n",
      "frame 69\n",
      "gripper closed True\n",
      "frame 70\n",
      "gripper closed True\n",
      "frame 71\n",
      "gripper closed True\n",
      "frame 72\n",
      "gripper closed True\n",
      "frame 73\n",
      "gripper closed True\n",
      "frame 74\n",
      "gripper closed True\n",
      "frame 75\n",
      "gripper closed True\n",
      "frame 76\n",
      "gripper closed True\n",
      "frame 77\n",
      "gripper closed True\n",
      "frame 78\n",
      "gripper closed True\n",
      "frame 79\n",
      "gripper closed True\n",
      "frame 80\n",
      "gripper closed True\n",
      "frame 81\n",
      "gripper closed True\n",
      "frame 82\n",
      "gripper closed True\n",
      "frame 83\n",
      "gripper closed True\n",
      "frame 84\n",
      "gripper closed True\n",
      "frame 85\n",
      "gripper closed True\n",
      "frame 86\n",
      "gripper closed True\n",
      "frame 87\n",
      "gripper closed True\n",
      "frame 88\n",
      "gripper closed True\n",
      "frame 89\n",
      "gripper closed True\n",
      "frame 90\n",
      "gripper closed True\n",
      "frame 91\n",
      "gripper closed True\n",
      "frame 92\n",
      "gripper closed True\n",
      "frame 93\n",
      "gripper closed True\n",
      "frame 94\n",
      "gripper closed True\n",
      "frame 95\n",
      "gripper closed True\n",
      "frame 96\n",
      "gripper closed True\n",
      "frame 97\n",
      "gripper closed True\n",
      "frame 98\n",
      "gripper closed True\n",
      "frame 99\n",
      "gripper closed True\n",
      "frame 100\n",
      "gripper closed True\n",
      "frame 101\n",
      "gripper closed True\n",
      "frame 102\n",
      "gripper closed True\n",
      "frame 103\n",
      "gripper closed True\n",
      "frame 104\n",
      "gripper closed True\n",
      "frame 105\n",
      "gripper closed True\n",
      "frame 106\n",
      "gripper closed True\n",
      "frame 107\n",
      "gripper closed True\n",
      "frame 108\n",
      "gripper closed True\n",
      "frame 109\n",
      "gripper closed True\n",
      "frame 110\n",
      "gripper closed True\n",
      "frame 111\n",
      "gripper closed True\n",
      "frame 112\n",
      "gripper closed True\n",
      "frame 113\n",
      "gripper closed True\n",
      "frame 114\n"
     ]
    }
   ],
   "source": [
    "# MV\n",
    "from src.my_loader import DetectAndSegment\n",
    "from pathlib import Path\n",
    "\n",
    "#   1 data/droid_raw/1.0.1/success/2023-03-02/Thu_Mar__2_15_03_35_2023\n",
    "#   2 data/droid_raw/1.0.1/success/2023-03-02/Thu_Mar__2_16_51_12_2023\n",
    "#   3 data/droid_raw/1.0.1/success/2023-03-02/Thu_Mar__2_18_13_38_2023 +\n",
    "#   4 data/droid_raw/1.0.1/success/2023-03-03/Fri_Mar__3_15_30_17_2023\n",
    "#   5 data/droid_raw/1.0.1/success/2023-03-06/Mon_Mar__6_16_02_37_2023 +\n",
    "#   6 data/droid_raw/1.0.1/success/2023-03-06/Mon_Mar__6_17_06_52_2023 X too dark\n",
    "#   7 data/droid_raw/1.0.1/success/2023-03-07/Tue_Mar__7_15_36_10_2023\n",
    "#   8 data/droid_raw/1.0.1/success/2023-03-07/Tue_Mar__7_16_20_41_2023\n",
    "#   9 data/droid_raw/1.0.1/success/2023-03-07/Tue_Mar__7_17_59_19_2023\n",
    "#  10 data/droid_raw/1.0.1/success/2023-03-08/Wed_Mar__8_13_29_47_2023\n",
    "#  11 data/droid_raw/1.0.1/success/2023-03-08/Wed_Mar__8_14_45_19_2023\n",
    "#  12 data/droid_raw/1.0.1/success/2023-03-08/Wed_Mar__8_16_45_10_2023 X\n",
    "#  13 data/droid_raw/1.0.1/success/2023-03-08/Wed_Mar__8_19_32_03_2023\n",
    "#  14 data/droid_raw/1.0.1/success/2023-03-08/Wed_Mar__8_19_51_18_2023\n",
    "#  15 data/droid_raw/1.0.1/success/2023-03-09/Thu_Mar__9_18_14_34_2023 X\n",
    "#  16 data/droid_raw/1.0.1/success/2023-03-09/Thu_Mar__9_18_47_35_2023 +\n",
    "#  17 data/droid_raw/1.0.1/success/2023-03-09/Thu_Mar__9_19_48_15_2023\n",
    "#  18 data/droid_raw/1.0.1/success/2023-04-07/Fri_Apr__7_13_32_40_2023 X\n",
    "#  19 data/droid_raw/1.0.1/success/2023-04-12/Wed_Apr_12_14:13:32_2023 OK\n",
    "#  20 data/droid_raw/1.0.1/success/2023-04-12/Wed_Apr_12_15:09:51_2023\n",
    "\n",
    "# src/raw.py --visualize  --scene data/droid_raw/1.0.1/success/2023-04-07/Fri_Apr__7_13_32_40_2023\n",
    "scene =                          \"data/droid_raw/1.0.1/success/2023-03-08/Wed_Mar__8_16_45_10_2023\"\n",
    "loader = DetectAndSegment(Path(scene))\n",
    "loader.read_trajectory()\n",
    "loaders: List = [loader]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 68)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.get_start_stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loader.rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Object Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.72it/s]\n"
     ]
    }
   ],
   "source": [
    "from DITTO.trajectory import Trajectory\n",
    "\n",
    "num_frames = -1 # TIME_STEPS  # number of frames through which we compute flow\n",
    "trajectories: Dict[int, Trajectory] = {}\n",
    "for demonstration_index in tqdm(range(len(loaders))):\n",
    "    trajectories[demonstration_index] = Trajectory.from_hands23(loaders[demonstration_index], n_frames=num_frames)\n",
    "\n",
    "# We could pre compute trajectories with .trajectory_2D and .trajectory_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argusm/lang/RAFT/core/raft.py:99: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.args.mixed_precision):\n",
      "/home/argusm/lang/RAFT/core/raft.py:110: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.args.mixed_precision):\n",
      "/home/argusm/lang/RAFT/core/raft.py:127: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.args.mixed_precision):\n"
     ]
    }
   ],
   "source": [
    "trajectory = trajectories[0].trajectory_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need n points, not n - 1\n",
    "start, stop = loader.get_start_stop()\n",
    "n = stop - start + 1\n",
    "full_trajectory = np.zeros((n, 1, 2))\n",
    "full_trajectory[1:n] = trajectory\n",
    "full_trajectory[0] = trajectory[0]\n",
    "trajectory = full_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/trajectory.npy\", \"wb\") as f:\n",
    "    np.save(f, trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 467.,  857.]],\n",
       "\n",
       "       [[ 467.,  857.]],\n",
       "\n",
       "       [[ 467.,  857.]],\n",
       "\n",
       "       [[ 467.,  857.]],\n",
       "\n",
       "       [[ 467.,  859.]],\n",
       "\n",
       "       [[ 467.,  859.]],\n",
       "\n",
       "       [[ 467.,  859.]],\n",
       "\n",
       "       [[ 467.,  859.]],\n",
       "\n",
       "       [[ 467.,  859.]],\n",
       "\n",
       "       [[ 466.,  860.]],\n",
       "\n",
       "       [[ 465.,  862.]],\n",
       "\n",
       "       [[ 460.,  868.]],\n",
       "\n",
       "       [[ 453.,  875.]],\n",
       "\n",
       "       [[ 443.,  885.]],\n",
       "\n",
       "       [[ 431.,  897.]],\n",
       "\n",
       "       [[ 415.,  912.]],\n",
       "\n",
       "       [[ 405.,  922.]],\n",
       "\n",
       "       [[ 396.,  930.]],\n",
       "\n",
       "       [[ 387.,  937.]],\n",
       "\n",
       "       [[ 382.,  939.]],\n",
       "\n",
       "       [[ 379.,  940.]],\n",
       "\n",
       "       [[ 377.,  939.]],\n",
       "\n",
       "       [[ 375.,  940.]],\n",
       "\n",
       "       [[ 375.,  941.]],\n",
       "\n",
       "       [[ 375.,  945.]],\n",
       "\n",
       "       [[ 376.,  951.]],\n",
       "\n",
       "       [[ 377.,  957.]],\n",
       "\n",
       "       [[ 380.,  963.]],\n",
       "\n",
       "       [[ 384.,  972.]],\n",
       "\n",
       "       [[ 388.,  979.]],\n",
       "\n",
       "       [[ 392.,  988.]],\n",
       "\n",
       "       [[ 394.,  993.]],\n",
       "\n",
       "       [[ 396.,  996.]],\n",
       "\n",
       "       [[ 396.,  999.]],\n",
       "\n",
       "       [[ 395., 1000.]],\n",
       "\n",
       "       [[ 393., 1000.]],\n",
       "\n",
       "       [[ 392., 1000.]],\n",
       "\n",
       "       [[ 392., 1000.]],\n",
       "\n",
       "       [[ 392., 1000.]],\n",
       "\n",
       "       [[ 392., 1000.]],\n",
       "\n",
       "       [[ 391.,  995.]],\n",
       "\n",
       "       [[ 388.,  989.]],\n",
       "\n",
       "       [[ 385.,  983.]],\n",
       "\n",
       "       [[ 385.,  980.]],\n",
       "\n",
       "       [[ 385.,  979.]],\n",
       "\n",
       "       [[ 406.,  970.]],\n",
       "\n",
       "       [[ 426.,  958.]],\n",
       "\n",
       "       [[ 435.,  951.]],\n",
       "\n",
       "       [[ 447.,  938.]],\n",
       "\n",
       "       [[ 453.,  927.]],\n",
       "\n",
       "       [[ 457.,  917.]],\n",
       "\n",
       "       [[ 459.,  907.]],\n",
       "\n",
       "       [[ 459.,  898.]],\n",
       "\n",
       "       [[ 458.,  891.]],\n",
       "\n",
       "       [[ 458.,  885.]],\n",
       "\n",
       "       [[ 457.,  880.]],\n",
       "\n",
       "       [[ 456.,  875.]],\n",
       "\n",
       "       [[ 456.,  870.]],\n",
       "\n",
       "       [[ 456.,  867.]],\n",
       "\n",
       "       [[ 458.,  864.]],\n",
       "\n",
       "       [[ 461.,  862.]],\n",
       "\n",
       "       [[ 464.,  860.]],\n",
       "\n",
       "       [[ 468.,  857.]],\n",
       "\n",
       "       [[ 474.,  853.]],\n",
       "\n",
       "       [[ 479.,  850.]],\n",
       "\n",
       "       [[ 485.,  844.]],\n",
       "\n",
       "       [[ 490.,  839.]],\n",
       "\n",
       "       [[ 494.,  835.]],\n",
       "\n",
       "       [[ 501.,  828.]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Recordings\n",
    "\n",
    "Using an interactive viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DITTO.notebook_utils import plot_preds\n",
    "from DITTO.vis_helpers import overlay_mask_edge\n",
    "\n",
    "\n",
    "def annotate_initial_frame(loader, traj, ax, image, frame_index):\n",
    "    ax.scatter(*traj.keypoints_2D[0, ::-1], marker=\"x\", c=\"yellow\")\n",
    "    ax.scatter(*traj.goal_keypoints_2D[0, ::-1], marker=\"x\", c=\"r\")\n",
    "    if frame_index != 0:\n",
    "        return image\n",
    "    start_frame, stop_frame = loader.get_start_stop()\n",
    "    \n",
    "    mask = loader.get_object_mask(start_frame)[:, :, 0]\n",
    "    image = overlay_mask_edge(image, mask, color=(255, 255, 0))\n",
    "    mask = traj.goal_mask\n",
    "    image = overlay_mask_edge(image, mask, color=(255, 0, 0))\n",
    "    return image\n",
    "\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(1, figsize=(8, 6))\n",
    "fig.suptitle(\"Demonstration Frames\")\n",
    "ax.set_axis_off()\n",
    "image_h = ax.imshow(loaders[demo_index].get_rgb(0))\n",
    "\n",
    "def update(demo_index, frame_index):\n",
    "    demo_len = loaders[demo_index].get_len()\n",
    "    if frame_index >= demo_len:\n",
    "        print(f\"invalid frame index: {frame_index}, demo length: {demo_len}\")\n",
    "        frame_index = demo_len - 1\n",
    "    image = loaders[demo_index].get_rgb(frame_index)\n",
    "    mask = loaders[demo_index].get_object_mask(frame_index)[:, :, 0]\n",
    "    image = overlay_mask_edge(image, mask)\n",
    "    # plot hands & object bbox preds\n",
    "    plot_preds(loaders[demo_index], frame_index, ax)\n",
    "    traj = trajectories[demo_index]\n",
    "    image = annotate_initial_frame(loaders[demo_index], traj, ax, image, frame_index)\n",
    "    \n",
    "    image_h.set_data(image)\n",
    "    fig.canvas.draw_idle()\n",
    "    fig.canvas.flush_events()\n",
    "\n",
    "max_frames_i = max([len(loader) for loader in loaders]) - 1\n",
    "slider_w = ipywidgets.widgets.IntSlider(\n",
    "    min=0, max=len(loaders) - 1, step=1, value=0, layout=ipywidgets.Layout(width=\"70%\"))\n",
    "slider_i = ipywidgets.widgets.IntSlider(\n",
    "    min=0, max=max_frames_i, step=1, value=0, layout=ipywidgets.Layout(width=\"70%\"))\n",
    "ipywidgets.interact(update, demo_index=slider_w, frame_index=slider_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show 3D Traj.\n",
    "\n",
    "Find the full 3D pose, with rotations, by looking at sequential frames of the demonstration video, and fitting transformations.\n",
    "\n",
    "This uses RANSAC, however the parameters for this still need to be tuned.\n",
    "\n",
    "The pointcloud poses look quite good, but there is quite a bit of variance in the pose measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from DITTO.tracking_3D import Step3DMethod\n",
    "\n",
    "# trajectories[demo_index]._step_function_3D = Step3DMethod.loftr_ransac\n",
    "# trajectories[demo_index].reset_cached()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_index = 0\n",
    "live_indices = set(range(len(loaders)))\n",
    "live_indices.remove(demo_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/heppert/datasets/video_imitation/recordings_24_01_05/tennisball_cup/003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:13<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point Error [000]: 0.00 [mm]\n",
      "Point Error [001]: 0.78 [mm]\n",
      "Point Error [002]: 1.19 [mm]\n",
      "Point Error [003]: 1.14 [mm]\n",
      "Point Error [004]: 1.36 [mm]\n",
      "Point Error [005]: 0.98 [mm]\n",
      "Point Error [006]: 0.79 [mm]\n",
      "Point Error [007]: 1.38 [mm]\n",
      "Point Error [008]: 2.87 [mm]\n",
      "Point Error [009]: 2.37 [mm]\n",
      "Point Error [010]: 4.47 [mm]\n"
     ]
    }
   ],
   "source": [
    "# Plot relative demo trajectory\n",
    "o3d_objects = []\n",
    "print(loaders[demo_index].recording_path)\n",
    "\n",
    "for idx, transform in enumerate(trajectories[demo_index].trajectory_3D):\n",
    "    abs_point_from_2_5_D = trajectories[demo_index].lifted_2D_trajectory[\n",
    "        idx, 0, :  # Again, this is all keypoints\n",
    "    ]\n",
    "\n",
    "    print(\n",
    "        f\"Point Error [{idx:03d}]: {np.linalg.norm(transform[:3, 3] - abs_point_from_2_5_D) * 1000:.02f} [mm]\"\n",
    "    )\n",
    "\n",
    "    o3d_objects.append(\n",
    "        casino.visualization.get_o3d_coordinate_frame(scale=0.1, transform=transform)\n",
    "    )\n",
    "    o3d_objects.append(\n",
    "        casino.visualization.get_o3d_coordinate_frame(\n",
    "            scale=0.05, position=abs_point_from_2_5_D\n",
    "        )\n",
    "    )\n",
    "\n",
    "pcd = loaders[demo_index].get_pointcloud_o3d(0)\n",
    "\n",
    "o3d.visualization.draw_geometries(\n",
    "    [\n",
    "        pcd,\n",
    "        *o3d_objects,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the 3D trajectory to the lifted one.\n",
    "trajectories[demo_index].trajectory_3D\n",
    "\n",
    "trajectory_3d = trajectories[demo_index].trajectory_3D[..., :3, 3]\n",
    "trajectory_lifted = trajectories[demo_index].lifted_2D_trajectory[:, 0,  :]\n",
    "\n",
    "l2_error = np.linalg.norm(trajectory_3d - trajectory_lifted, axis=-1).mean()\n",
    "print(f\"Mean Point Error: {l2_error*1000:.02f} [mm] \\t <- 3D vs lifted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_start, pc_rgb_start = casino.pointcloud.get_pc(\n",
    "    trajectories[demo_index].depth_start,\n",
    "    trajectories[demo_index].intrinsics,\n",
    "    rgb=trajectories[demo_index].rgb_start,\n",
    ")\n",
    "\n",
    "pcd = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(pc_start))\n",
    "pcd.colors = o3d.utility.Vector3dVector(pc_rgb_start / 255.0)\n",
    "o3d.visualization.draw_geometries(\n",
    "    [\n",
    "        pcd,\n",
    "        casino.visualization.get_o3d_coordinate_frame(\n",
    "            scale=0.1, transform=trajectories[demo_index].hand_pose_3D\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warp Demo Traj. to Live View"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warp 3D with Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot relative demo trajectory\n",
    "for live_index in live_indices:\n",
    "    o3d_objects = []\n",
    "\n",
    "    # This could come from anywhere but for now we just use another trajecory\n",
    "    rgb_live = trajectories[live_index].rgb_start\n",
    "    xyz_live = casino.pointcloud.get_xyz(\n",
    "        trajectories[live_index].depth_start, trajectories[live_index].intrinsics\n",
    "    )\n",
    "\n",
    "    # this takes a pre-computed trajectory, and demo mask of the initial frame, and warps it the live frame.\n",
    "    warped_3D_trajectory = trajectories[demo_index].warp_3D_onto_live_frame(\n",
    "        rgb_live, xyz_live, debug_vis=True\n",
    "    )\n",
    "\n",
    "    # Assuming we roughly moved the same, we can visualize the original trajectory\n",
    "    live_3D_trajectory = trajectories[live_index].trajectory_3D\n",
    "\n",
    "    for warped_transform, live_transform in zip(\n",
    "        warped_3D_trajectory, live_3D_trajectory\n",
    "    ):  # relative transformation between frames\n",
    "        o3d_objects.append(\n",
    "            casino.visualization.get_o3d_coordinate_frame(\n",
    "                scale=0.1, transform=warped_transform\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # o3d_objects.append(\n",
    "        #     casino.visualization.get_o3d_coordinate_frame(\n",
    "        #         scale=0.05, transform=live_transform\n",
    "        #     )\n",
    "        # )\n",
    "\n",
    "    # Get scene point cloud\n",
    "    pc_start, pc_rgb_start = casino.pointcloud.get_pc(\n",
    "        trajectories[live_index].depth_start,\n",
    "        trajectories[live_index].intrinsics,\n",
    "        rgb=trajectories[live_index].rgb_start,\n",
    "    )\n",
    "\n",
    "    pcd = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(pc_start))\n",
    "    pcd.colors = o3d.utility.Vector3dVector(pc_rgb_start / 255.0)\n",
    "    o3d.visualization.draw_geometries(\n",
    "        [\n",
    "            pcd,\n",
    "            *o3d_objects,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warp 3D with Goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot relative demo trajectory\n",
    "for live_index in live_indices:\n",
    "    # Hard example for coke_tray, when demo_index = 0\n",
    "    live_index = 5\n",
    "\n",
    "    o3d_objects = []\n",
    "\n",
    "    # This could come from anywhere but for now we just use another trajecory\n",
    "    rgb_live = trajectories[live_index].rgb_start\n",
    "    xyz_live = casino.pointcloud.get_xyz(\n",
    "        trajectories[live_index].depth_start, trajectories[live_index].intrinsics\n",
    "    )\n",
    "\n",
    "    # this takes a pre-computed trajectory, and demo mask of the initial frame, and warps it the live frame.\n",
    "    warped_3D_trajectory = trajectories[demo_index].warp_3D_onto_live_frame(\n",
    "        rgb_live, xyz_live, use_goal_mask=True, debug_vis=True\n",
    "    )\n",
    "\n",
    "    # Assuming we roughly moved the same, we can visualize the original trajectory\n",
    "    live_3D_trajectory = trajectories[live_index].trajectory_3D\n",
    "\n",
    "    for warped_transform, live_transform in zip(\n",
    "        warped_3D_trajectory, live_3D_trajectory\n",
    "    ):  # relative transformation between frames\n",
    "        o3d_objects.append(\n",
    "            casino.visualization.get_o3d_coordinate_frame(\n",
    "                scale=0.1, transform=warped_transform\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # o3d_objects.append(\n",
    "        #     casino.visualization.get_o3d_coordinate_frame(\n",
    "        #         scale=0.05, transform=live_transform\n",
    "        #     )\n",
    "        # )\n",
    "\n",
    "    # Get scene point cloud\n",
    "    pc_start, pc_rgb_start = casino.pointcloud.get_pc(\n",
    "        trajectories[live_index].depth_start,\n",
    "        trajectories[live_index].intrinsics,\n",
    "        rgb=trajectories[live_index].rgb_start,\n",
    "    )\n",
    "\n",
    "    pcd = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(pc_start))\n",
    "    pcd.colors = o3d.utility.Vector3dVector(pc_rgb_start / 255.0)\n",
    "    o3d.visualization.draw_geometries(\n",
    "        [\n",
    "            pcd,\n",
    "            *o3d_objects,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trajectory Mixing\n",
    "\n",
    "Mixing can only be done, if there is a define goal position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory Mixing in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DITTO.mixing import mix_3D\n",
    "\n",
    "PLOT_3D_TRAJECTORIES = True\n",
    "from flow_control.utils_coords import matrix_to_pos_orn, pos_orn_to_matrix\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "def eval_trajectory_3d(trajectory, estimate, label=\"\"):\n",
    "    assert trajectory.ndim == 3\n",
    "    assert trajectory.shape[1] == 4\n",
    "    assert trajectory.shape[2] == 4\n",
    "    diff_orn = np.mean((R.from_matrix(trajectory[:,:3,:3]).inv() * R.from_matrix(estimate[:,:3,:3])).magnitude())\n",
    "    diff_mm = np.mean(np.linalg.norm(trajectory[:, :3, 3] - estimate[:, :3, 3], axis=1))\n",
    "    print(f\"{label}: {diff_mm:.3f}, {diff_orn:.3f} in 3D\")\n",
    "    \n",
    "    \n",
    "# Plot relative demo trajectory\n",
    "for live_index in live_indices:\n",
    "    # Hard example when coke_tray is selected and demo_index = 0\n",
    "    live_index = 5 \n",
    "\n",
    "    # This could come from anywhere but for now we just use another trajecory\n",
    "    rgb_live = trajectories[live_index].rgb_start\n",
    "    xyz_live = casino.pointcloud.get_xyz(\n",
    "        trajectories[live_index].depth_start, trajectories[live_index].intrinsics\n",
    "    )\n",
    "\n",
    "    # this takes a pre-computed trajectory, and demo mask of the initial frame, and warps it the live frame.\n",
    "    object_warped_3D_trajectory = trajectories[demo_index].warp_3D_onto_live_frame(\n",
    "        rgb_live, xyz_live, use_goal_mask=False\n",
    "    )\n",
    "    goal_warped_3D_trajectory = trajectories[demo_index].warp_3D_onto_live_frame(\n",
    "        rgb_live, xyz_live, use_goal_mask=True\n",
    "    )\n",
    "\n",
    "    warped_3D_trajectory = mix_3D(\n",
    "        object_warped_3D_trajectory, goal_warped_3D_trajectory\n",
    "    )\n",
    "\n",
    "    live_3D_trajectory = trajectories[live_index].trajectory_3D\n",
    "\n",
    "    # Quantatative Evaluation\n",
    "    eval_trajectory_3d(live_3D_trajectory, object_warped_3D_trajectory, \"obj\")\n",
    "    eval_trajectory_3d(live_3D_trajectory, goal_warped_3D_trajectory, \"goal\")\n",
    "    eval_trajectory_3d(live_3D_trajectory, warped_3D_trajectory, \"mix\")\n",
    "\n",
    "    # visualize\n",
    "    if PLOT_3D_TRAJECTORIES:\n",
    "        o3d_objects = []\n",
    "        \n",
    "        for warped_transform, live_transform in zip(\n",
    "            warped_3D_trajectory, live_3D_trajectory\n",
    "        ):  # relative transformation between frames\n",
    "            o3d_objects.append(\n",
    "                casino.visualization.get_o3d_coordinate_frame(\n",
    "                    scale=0.1, transform=warped_transform\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # o3d_objects.append(\n",
    "            #     casino.visualization.get_o3d_coordinate_frame(\n",
    "            #         scale=0.05, transform=live_transform\n",
    "            #     )\n",
    "            # )\n",
    "\n",
    "        # Get scene point cloud\n",
    "        pc_start, pc_rgb_start = casino.pointcloud.get_pc(\n",
    "            trajectories[live_index].depth_start,\n",
    "            trajectories[live_index].intrinsics,\n",
    "            rgb=trajectories[live_index].rgb_start,\n",
    "        )\n",
    "\n",
    "        pcd = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(pc_start))\n",
    "        pcd.colors = o3d.utility.Vector3dVector(pc_rgb_start / 255.0)\n",
    "        o3d.visualization.draw_geometries(\n",
    "            [\n",
    "                pcd,\n",
    "                *o3d_objects,\n",
    "            ]\n",
    "        )\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warp the Hand Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot relative demo trajectory\n",
    "for live_index in live_indices:\n",
    "    o3d_objects = []\n",
    "\n",
    "    # This could come from anywhere but for now we just use another trajecory\n",
    "    rgb_live = trajectories[live_index].rgb_start\n",
    "    xyz_live = casino.pointcloud.get_xyz(\n",
    "        trajectories[live_index].depth_start, trajectories[live_index].intrinsics\n",
    "    )\n",
    "\n",
    "    # This warpes the hand\n",
    "    warped_3D_hand_pose = trajectories[demo_index].warp_3D_hand_onto_live_frame(\n",
    "        rgb_live, xyz_live\n",
    "    )\n",
    "\n",
    "    # Get scene point cloud\n",
    "    pc_start, pc_rgb_start = casino.pointcloud.get_pc(\n",
    "        trajectories[live_index].depth_start,\n",
    "        trajectories[live_index].intrinsics,\n",
    "        rgb=trajectories[live_index].rgb_start,\n",
    "    )\n",
    "\n",
    "    pcd = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(pc_start))\n",
    "    pcd.colors = o3d.utility.Vector3dVector(pc_rgb_start / 255.0)\n",
    "    o3d.visualization.draw_geometries(\n",
    "        [\n",
    "            pcd,\n",
    "            casino.visualization.get_o3d_coordinate_frame(\n",
    "                scale=0.1, transform=warped_3D_hand_pose\n",
    "            ),\n",
    "        ]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "a24b81a1d149b501635bc7583842bbebcc03d90989b2d1f6f5e3f71ffb85bdd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
