{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "474a6c3d-9ed4-4ce2-9b78-f6c16838ca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from skimage.transform import rescale, resize\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy import ndimage\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "# from transformers import Dinov2Backbone\n",
    "from torchvision.models import resnet18, resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54183ad0-c0be-4387-8645-ad1cca0d0117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iternal/miniconda3/envs/rerun/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/iternal/miniconda3/envs/rerun/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (9): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_dir = Path.home() / \"work/brox/python-example-droid-dataset\"\n",
    "backbone = resnet50(pretrained=True)\n",
    "children = list(backbone.children())\n",
    "newmodel = torch.nn.Sequential(*children[0:10])\n",
    "newmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91e14882-1c42-43cb-b298-6d68e734579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imginfo = lambda img: print(type(img), img.dtype, img.shape, img.min(), img.max())\n",
    "\n",
    "# === load first touch coors\n",
    "import json\n",
    "with open(code_dir / \"data/single_log.json\") as f:\n",
    "    episode_log = json.load(f)\n",
    "first_x, first_y, first_z = map(int, episode_log[\"first_touch\"])\n",
    "cropw = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9c7b50f-84d1-4219-b96a-3bebd91af5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === first image VS max distant image during grip\n",
    "data_path = code_dir / \"data/frames\"\n",
    "file_list = sorted(data_path.glob(\"center*jpg\"))\n",
    "first_image = io.imread(file_list[0])\n",
    "mid_image = io.imread(file_list[-1])\n",
    "max_image = io.imread(data_path / \"max_image.jpg\")\n",
    "\n",
    "h, w = first_image.shape[:2]\n",
    "if (0 <= first_y - cropw and first_y + cropw < h and\n",
    "    0 <= first_x - cropw and first_x + cropw < w):\n",
    "    good_episode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1e8e4b5-358b-4e91-aac8-bc486ca37648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_batch(image):\n",
    "    downscaled = resize(image, (224, 224))\n",
    "    #batch = torch.from_numpy(downscaled)[None, :, :, :].to(torch.float32) / 255 # [h, w, c] -> [1, h, w, c]\n",
    "    #batch = batch.permute(0, 3, 1, 2)  # [1, h, w, c] -> [1, c, h, w]\n",
    "\n",
    "    batch = torch.from)image / 255\n",
    "\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    batch = preprocess(batch)\n",
    "    imginfo(batch)\n",
    "    \n",
    "    return batch\n",
    "\n",
    "def cut_crop(image):\n",
    "    \"\"\"\n",
    "    :param image: [h, w, c]\n",
    "    \"\"\"\n",
    "    return image[first_y-cropw:first_y+cropw, first_x-cropw:first_x+cropw]\n",
    "\n",
    "save_images = {\n",
    "    \"crop_first\": cut_crop(first_image),\n",
    "    \"crop_max\": cut_crop(max_image)\n",
    "}\n",
    "\n",
    "for name, image in save_images.items():\n",
    "    io.imsave(data_path / (name + \".jpg\"), image.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "478f071a-3a19-4fb2-8d73-81fabd78b99f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Unexpected type <class 'numpy.ndarray'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# === Run resnet on crops\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dino1 \u001b[38;5;241m=\u001b[39m newmodel(to_batch(cut_crop(first_image)))\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;66;03m# [1, c, h, w] range [0, 1] torch.float32\u001b[39;00m\n\u001b[1;32m      3\u001b[0m dino2 \u001b[38;5;241m=\u001b[39m newmodel(to_batch(cut_crop(max_image)))\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcos_sim\u001b[39m(vec1: np\u001b[38;5;241m.\u001b[39mndarray, vec2: np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# (vec1, vec2) = |vec1||vec2|cos alpha\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 14\u001b[0m, in \u001b[0;36mto_batch\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m      6\u001b[0m batch \u001b[38;5;241m=\u001b[39m image \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m\n\u001b[1;32m      8\u001b[0m preprocess \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m      9\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize(\u001b[38;5;241m256\u001b[39m),\n\u001b[1;32m     10\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mCenterCrop(\u001b[38;5;241m224\u001b[39m),\n\u001b[1;32m     11\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m     12\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize(mean\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m], std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m]),\n\u001b[1;32m     13\u001b[0m ])\n\u001b[0;32m---> 14\u001b[0m batch \u001b[38;5;241m=\u001b[39m preprocess(batch)\n\u001b[1;32m     15\u001b[0m imginfo(batch)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "File \u001b[0;32m~/miniconda3/envs/rerun/lib/python3.11/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m t(img)\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/miniconda3/envs/rerun/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/rerun/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rerun/lib/python3.11/site-packages/torchvision/transforms/transforms.py:361\u001b[0m, in \u001b[0;36mResize.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m    354\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;124;03m        img (PIL Image or Tensor): Image to be scaled.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03m        PIL Image or Tensor: Rescaled image.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mresize(img, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterpolation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mantialias)\n",
      "File \u001b[0;32m~/miniconda3/envs/rerun/lib/python3.11/site-packages/torchvision/transforms/functional.py:476\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m max_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    471\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    472\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_size should only be passed if size specifies the length of the smaller edge, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    473\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi.e. size should be an int or a sequence of length 1 in torchscript mode.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    474\u001b[0m         )\n\u001b[0;32m--> 476\u001b[0m _, image_height, image_width \u001b[38;5;241m=\u001b[39m get_dimensions(img)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(size, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    478\u001b[0m     size \u001b[38;5;241m=\u001b[39m [size]\n",
      "File \u001b[0;32m~/miniconda3/envs/rerun/lib/python3.11/site-packages/torchvision/transforms/functional.py:78\u001b[0m, in \u001b[0;36mget_dimensions\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mget_dimensions(img)\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_pil\u001b[38;5;241m.\u001b[39mget_dimensions(img)\n",
      "File \u001b[0;32m~/miniconda3/envs/rerun/lib/python3.11/site-packages/torchvision/transforms/_functional_pil.py:31\u001b[0m, in \u001b[0;36mget_dimensions\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     29\u001b[0m     width, height \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39msize\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [channels, height, width]\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(img)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Unexpected type <class 'numpy.ndarray'>"
     ]
    }
   ],
   "source": [
    "# === Run resnet on crops\n",
    "dino1 = newmodel(to_batch(cut_crop(first_image))).detach() # [1, c, h, w] range [0, 1] torch.float32\n",
    "dino2 = newmodel(to_batch(cut_crop(max_image))).detach()\n",
    "\n",
    "def cos_sim(vec1: np.ndarray, vec2: np.ndarray):\n",
    "    # (vec1, vec2) = |vec1||vec2|cos alpha\n",
    "    return np.sum(vec1 * vec2) / np.linalg.norm(vec1) / np.linalg.norm(vec2)\n",
    "\n",
    "v1 = dino1.flatten().numpy()\n",
    "v2 = dino2.flatten().numpy()\n",
    "cos_sim(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8834b009-f572-43bc-8897-2289eeee7506",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 50\n",
    "x, y = 795, 363\n",
    "crop = first_image[y-s:y+s, x-s:x+s]\n",
    "#io.imsave(data_path / (\"small.jpg\"), crop.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac4b358e-5eb6-426e-8c35-0f369895b949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9982982"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 100\n",
    "x, y = 795, 363\n",
    "crop = first_image[y-s:y+s, x-s:x+s]\n",
    "dino1 = newmodel(to_batch(crop)).detach()\n",
    "\n",
    "s = 100\n",
    "x, y = 750, 360\n",
    "crop = first_image[y-s:y+s, x-s:x+s]\n",
    "dino2 = newmodel(to_batch(crop)).detach()\n",
    "\n",
    "v1 = dino1.flatten().numpy()\n",
    "v2 = dino2.flatten().numpy()\n",
    "cos_sim(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73e9d283-bcf0-42ec-a97b-ac110614b572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.float32 torch.Size([1, 3, 224, 224]) tensor(-2.1179) tensor(-1.7870)\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "# === just run resnet\n",
    "image = io.imread(code_dir / \"data/penguin.jpg\")\n",
    "h, w, c = image.shape\n",
    "image = image[:, w//2-h//2:w//2+h//2]\n",
    "\n",
    "v = backbone(to_batch(image)).detach()\n",
    "pred_probs = F.softmax(v[0], dim=0).cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2318e12e-dc34-4291-abe5-75dd98d3a866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(600, 0.006743107),\n",
       " (852, 0.005591981),\n",
       " (731, 0.0055306284),\n",
       " (463, 0.005397659),\n",
       " (733, 0.0042607603),\n",
       " (700, 0.004144021),\n",
       " (792, 0.0037841764),\n",
       " (837, 0.0037685703),\n",
       " (898, 0.0037080306),\n",
       " (618, 0.0035728852),\n",
       " (845, 0.0035567062),\n",
       " (836, 0.0035521074),\n",
       " (899, 0.0034810852),\n",
       " (784, 0.003459974),\n",
       " (523, 0.0034291914),\n",
       " (902, 0.0034145112),\n",
       " (515, 0.003413358),\n",
       " (728, 0.0032963085),\n",
       " (987, 0.0032383718),\n",
       " (587, 0.0032284337),\n",
       " (428, 0.0031915458),\n",
       " (447, 0.0031775096),\n",
       " (696, 0.0031581838),\n",
       " (488, 0.0031161313),\n",
       " (813, 0.0031005843),\n",
       " (851, 0.0030727931),\n",
       " (879, 0.0030680099),\n",
       " (676, 0.0030454095),\n",
       " (469, 0.0030447233),\n",
       " (412, 0.003011957),\n",
       " (769, 0.002968858),\n",
       " (758, 0.0029618328),\n",
       " (910, 0.0029563888),\n",
       " (409, 0.0029318084),\n",
       " (541, 0.0029209664),\n",
       " (151, 0.0028280187),\n",
       " (929, 0.0028185362),\n",
       " (840, 0.0027814151),\n",
       " (778, 0.0027719901),\n",
       " (749, 0.0027434537),\n",
       " (456, 0.0027335056),\n",
       " (818, 0.0027277102),\n",
       " (764, 0.0026953153),\n",
       " (722, 0.002686507),\n",
       " (868, 0.0026332168),\n",
       " (596, 0.0025742203),\n",
       " (674, 0.002545773),\n",
       " (427, 0.0025436599),\n",
       " (828, 0.0024801658),\n",
       " (830, 0.002473731),\n",
       " (666, 0.0024489027),\n",
       " (650, 0.0024391229),\n",
       " (641, 0.0024387857),\n",
       " (558, 0.0024375524),\n",
       " (462, 0.0023587102),\n",
       " (208, 0.0023325684),\n",
       " (876, 0.00232628),\n",
       " (861, 0.0023128456),\n",
       " (911, 0.0023080714),\n",
       " (998, 0.0022872428),\n",
       " (808, 0.0022817124),\n",
       " (882, 0.0022809117),\n",
       " (530, 0.002279546),\n",
       " (457, 0.0022735584),\n",
       " (620, 0.002265066),\n",
       " (577, 0.002263775),\n",
       " (872, 0.0022621907),\n",
       " (772, 0.0022590046),\n",
       " (606, 0.002254751),\n",
       " (636, 0.0022437528),\n",
       " (643, 0.002231881),\n",
       " (880, 0.002205006),\n",
       " (633, 0.0021927988),\n",
       " (539, 0.0021776746),\n",
       " (737, 0.0021754564),\n",
       " (567, 0.002141719),\n",
       " (850, 0.0021297948),\n",
       " (907, 0.0021150298),\n",
       " (440, 0.002099234),\n",
       " (805, 0.0020887249),\n",
       " (542, 0.002060543),\n",
       " (971, 0.0020532808),\n",
       " (487, 0.002049586),\n",
       " (921, 0.002038465),\n",
       " (811, 0.0020195073),\n",
       " (589, 0.0020158251),\n",
       " (954, 0.0020138095),\n",
       " (559, 0.0020115213),\n",
       " (574, 0.002004251),\n",
       " (356, 0.0020036104),\n",
       " (545, 0.002003494),\n",
       " (692, 0.0019747352),\n",
       " (494, 0.0019685589),\n",
       " (677, 0.0019682625),\n",
       " (616, 0.0019481211),\n",
       " (999, 0.0019243378),\n",
       " (504, 0.0019175153),\n",
       " (838, 0.0019123763),\n",
       " (862, 0.0019112597),\n",
       " (421, 0.0018930385),\n",
       " (725, 0.0018822923),\n",
       " (285, 0.0018510708),\n",
       " (254, 0.0018504764),\n",
       " (570, 0.0018338262),\n",
       " (823, 0.0018316786),\n",
       " (870, 0.0018315951),\n",
       " (761, 0.0018253839),\n",
       " (593, 0.0018237557),\n",
       " (419, 0.0018115985),\n",
       " (499, 0.0018095683),\n",
       " (281, 0.0018095063),\n",
       " (112, 0.0018019472),\n",
       " (740, 0.001801634),\n",
       " (519, 0.0018013084),\n",
       " (791, 0.0017969395),\n",
       " (502, 0.0017951966),\n",
       " (251, 0.001788402),\n",
       " (420, 0.0017827181),\n",
       " (754, 0.0017825293),\n",
       " (793, 0.0017772164),\n",
       " (855, 0.0017759773),\n",
       " (678, 0.001732336),\n",
       " (470, 0.0017226007),\n",
       " (518, 0.001719834),\n",
       " (626, 0.0017142924),\n",
       " (506, 0.0017132161),\n",
       " (912, 0.0017117406),\n",
       " (124, 0.0017062102),\n",
       " (223, 0.0016930319),\n",
       " (184, 0.0016919663),\n",
       " (968, 0.0016897744),\n",
       " (765, 0.0016891795),\n",
       " (522, 0.0016837951),\n",
       " (552, 0.0016811261),\n",
       " (892, 0.0016808031),\n",
       " (489, 0.0016796893),\n",
       " (782, 0.0016796782),\n",
       " (514, 0.0016705747),\n",
       " (918, 0.0016610632),\n",
       " (621, 0.0016609691),\n",
       " (638, 0.0016554215),\n",
       " (415, 0.0016541299),\n",
       " (691, 0.0016508761),\n",
       " (824, 0.001649502),\n",
       " (903, 0.0016468023),\n",
       " (491, 0.0016460747),\n",
       " (448, 0.0016359619),\n",
       " (610, 0.0016326725),\n",
       " (883, 0.0016320344),\n",
       " (435, 0.0016318308),\n",
       " (681, 0.0016271211),\n",
       " (582, 0.001623801),\n",
       " (195, 0.0016096095),\n",
       " (478, 0.0016042714),\n",
       " (608, 0.0016039804),\n",
       " (619, 0.0016027816),\n",
       " (186, 0.0015966696),\n",
       " (804, 0.0015944624),\n",
       " (904, 0.0015919363),\n",
       " (653, 0.0015912154),\n",
       " (599, 0.001589013),\n",
       " (171, 0.0015731008),\n",
       " (826, 0.001572721),\n",
       " (60, 0.001565493),\n",
       " (265, 0.0015622281),\n",
       " (783, 0.0015546229),\n",
       " (572, 0.001553211),\n",
       " (632, 0.0015529488),\n",
       " (680, 0.0015521646),\n",
       " (827, 0.0015506818),\n",
       " (585, 0.0015451598),\n",
       " (975, 0.0015371357),\n",
       " (849, 0.0015368673),\n",
       " (185, 0.0015337142),\n",
       " (948, 0.0015334856),\n",
       " (417, 0.0015312529),\n",
       " (738, 0.0015297028),\n",
       " (631, 0.001528138),\n",
       " (644, 0.0015203354),\n",
       " (163, 0.0015202204),\n",
       " (695, 0.0015157841),\n",
       " (557, 0.0015145674),\n",
       " (235, 0.0015143849),\n",
       " (505, 0.0015105921),\n",
       " (583, 0.0015020762),\n",
       " (673, 0.001496915),\n",
       " (199, 0.0014949148),\n",
       " (273, 0.0014931835),\n",
       " (787, 0.001491184),\n",
       " (859, 0.0014907229),\n",
       " (434, 0.0014794626),\n",
       " (459, 0.0014790242),\n",
       " (756, 0.0014715485),\n",
       " (711, 0.0014696453),\n",
       " (796, 0.0014659418),\n",
       " (455, 0.0014607665),\n",
       " (707, 0.0014596632),\n",
       " (282, 0.001458376),\n",
       " (637, 0.0014546819),\n",
       " (193, 0.001454025),\n",
       " (655, 0.0014507438),\n",
       " (231, 0.0014501191),\n",
       " (664, 0.0014463818),\n",
       " (512, 0.001441802),\n",
       " (753, 0.0014351624),\n",
       " (264, 0.0014306098),\n",
       " (238, 0.0014290658),\n",
       " (889, 0.001426598),\n",
       " (617, 0.0014259551),\n",
       " (699, 0.0014251054),\n",
       " (250, 0.001420174),\n",
       " (937, 0.001419467),\n",
       " (227, 0.0014167707),\n",
       " (767, 0.0014156951),\n",
       " (203, 0.0014001044),\n",
       " (716, 0.0013945563),\n",
       " (652, 0.0013931463),\n",
       " (762, 0.0013912478),\n",
       " (693, 0.0013887152),\n",
       " (253, 0.0013882705),\n",
       " (207, 0.0013870939),\n",
       " (464, 0.0013856484),\n",
       " (401, 0.0013822088),\n",
       " (786, 0.0013677402),\n",
       " (748, 0.0013598207),\n",
       " (797, 0.0013519346),\n",
       " (635, 0.00134422),\n",
       " (314, 0.0013441703),\n",
       " (189, 0.0013401543),\n",
       " (234, 0.001326658),\n",
       " (588, 0.0013247717),\n",
       " (667, 0.0013242014),\n",
       " (790, 0.0013203191),\n",
       " (284, 0.0013141778),\n",
       " (155, 0.0013054059),\n",
       " (896, 0.0013030613),\n",
       " (841, 0.0013015252),\n",
       " (977, 0.0013004779),\n",
       " (774, 0.0012997576),\n",
       " (684, 0.0012980759),\n",
       " (36, 0.0012980616),\n",
       " (683, 0.0012964999),\n",
       " (897, 0.0012933671),\n",
       " (341, 0.0012926392),\n",
       " (438, 0.0012894936),\n",
       " (611, 0.0012852397),\n",
       " (708, 0.0012844384),\n",
       " (192, 0.0012818613),\n",
       " (843, 0.0012818571),\n",
       " (461, 0.0012799214),\n",
       " (846, 0.001277326),\n",
       " (236, 0.0012728118),\n",
       " (358, 0.0012719792),\n",
       " (562, 0.001268614),\n",
       " (209, 0.0012681616),\n",
       " (604, 0.0012666733),\n",
       " (256, 0.0012659889),\n",
       " (501, 0.001265437),\n",
       " (966, 0.0012630658),\n",
       " (477, 0.0012617894),\n",
       " (916, 0.0012613543),\n",
       " (168, 0.001260268),\n",
       " (503, 0.001259544),\n",
       " (720, 0.0012568271),\n",
       " (747, 0.0012564888),\n",
       " (182, 0.0012488618),\n",
       " (776, 0.0012481017),\n",
       " (452, 0.0012460754),\n",
       " (513, 0.0012456352),\n",
       " (591, 0.001241875),\n",
       " (546, 0.0012398903),\n",
       " (584, 0.0012390458),\n",
       " (429, 0.0012381613),\n",
       " (799, 0.0012366975),\n",
       " (211, 0.0012315622),\n",
       " (248, 0.0012315208),\n",
       " (413, 0.0012295576),\n",
       " (178, 0.001224784),\n",
       " (267, 0.001219178),\n",
       " (909, 0.0012181987),\n",
       " (659, 0.0012138684),\n",
       " (773, 0.0012134581),\n",
       " (414, 0.0012057016),\n",
       " (710, 0.0011911438),\n",
       " (578, 0.0011905289),\n",
       " (775, 0.0011892305),\n",
       " (220, 0.0011863498),\n",
       " (225, 0.0011826471),\n",
       " (266, 0.0011796514),\n",
       " (770, 0.0011763325),\n",
       " (865, 0.0011760307),\n",
       " (543, 0.0011759741),\n",
       " (187, 0.0011725918),\n",
       " (719, 0.0011723139),\n",
       " (263, 0.0011620368),\n",
       " (242, 0.0011611118),\n",
       " (623, 0.0011606613),\n",
       " (191, 0.0011595335),\n",
       " (219, 0.0011590525),\n",
       " (919, 0.0011579581),\n",
       " (118, 0.001157603),\n",
       " (172, 0.0011575798),\n",
       " (766, 0.0011574762),\n",
       " (594, 0.0011542649),\n",
       " (426, 0.0011534683),\n",
       " (816, 0.0011523896),\n",
       " (752, 0.0011513614),\n",
       " (310, 0.0011513006),\n",
       " (742, 0.0011510059),\n",
       " (744, 0.0011501638),\n",
       " (646, 0.0011411645),\n",
       " (544, 0.0011381635),\n",
       " (479, 0.0011373261),\n",
       " (703, 0.0011345479),\n",
       " (471, 0.001133739),\n",
       " (432, 0.0011312668),\n",
       " (78, 0.0011307645),\n",
       " (566, 0.0011214477),\n",
       " (528, 0.001117089),\n",
       " (508, 0.0011160237),\n",
       " (704, 0.0011151946),\n",
       " (473, 0.001104069),\n",
       " (433, 0.0011035672),\n",
       " (622, 0.0011035422),\n",
       " (306, 0.0011028793),\n",
       " (605, 0.0011009809),\n",
       " (860, 0.0010999158),\n",
       " (224, 0.0010984731),\n",
       " (398, 0.001096721),\n",
       " (114, 0.0010948954),\n",
       " (87, 0.0010933839),\n",
       " (875, 0.0010865716),\n",
       " (355, 0.0010843584),\n",
       " (982, 0.0010843403),\n",
       " (188, 0.0010833307),\n",
       " (834, 0.0010827187),\n",
       " (240, 0.0010826328),\n",
       " (763, 0.0010794327),\n",
       " (202, 0.0010763318),\n",
       " (531, 0.0010744116),\n",
       " (842, 0.0010734987),\n",
       " (556, 0.0010726667),\n",
       " (113, 0.0010721928),\n",
       " (923, 0.0010681084),\n",
       " (338, 0.0010676169),\n",
       " (795, 0.0010634733),\n",
       " (161, 0.0010606331),\n",
       " (232, 0.0010597337),\n",
       " (943, 0.0010583708),\n",
       " (613, 0.0010556168),\n",
       " (7, 0.0010541078),\n",
       " (446, 0.0010540285),\n",
       " (160, 0.0010531698),\n",
       " (642, 0.001052907),\n",
       " (212, 0.0010523315),\n",
       " (313, 0.0010514538),\n",
       " (492, 0.0010508243),\n",
       " (395, 0.001049173),\n",
       " (226, 0.0010440537),\n",
       " (714, 0.0010435791),\n",
       " (259, 0.0010430724),\n",
       " (345, 0.0010404763),\n",
       " (183, 0.0010397652),\n",
       " (51, 0.0010395863),\n",
       " (179, 0.0010380362),\n",
       " (181, 0.0010376251),\n",
       " (257, 0.0010370404),\n",
       " (822, 0.0010355522),\n",
       " (173, 0.0010352975),\n",
       " (647, 0.001033965),\n",
       " (709, 0.0010324442),\n",
       " (475, 0.001032196),\n",
       " (978, 0.0010306706),\n",
       " (521, 0.0010293686),\n",
       " (750, 0.0010139423),\n",
       " (157, 0.0010133283),\n",
       " (568, 0.0010115756),\n",
       " (451, 0.0010088062),\n",
       " (885, 0.0010081232),\n",
       " (785, 0.001006397),\n",
       " (490, 0.0010041689),\n",
       " (162, 0.0010034948),\n",
       " (373, 0.0010019211),\n",
       " (917, 0.0009996551),\n",
       " (359, 0.0009989163),\n",
       " (418, 0.0009988127),\n",
       " (361, 0.0009973167),\n",
       " (723, 0.0009954219),\n",
       " (507, 0.0009925988),\n",
       " (819, 0.00099216),\n",
       " (283, 0.0009903728),\n",
       " (807, 0.0009899915),\n",
       " (534, 0.000987786),\n",
       " (932, 0.0009803816),\n",
       " (996, 0.0009785627),\n",
       " (777, 0.0009783816),\n",
       " (215, 0.000978337),\n",
       " (216, 0.0009763833),\n",
       " (950, 0.00097121304),\n",
       " (258, 0.00096903223),\n",
       " (222, 0.00096483325),\n",
       " (947, 0.000960947),\n",
       " (176, 0.00096094096),\n",
       " (197, 0.00095654425),\n",
       " (806, 0.0009540772),\n",
       " (516, 0.000951803),\n",
       " (730, 0.0009516155),\n",
       " (205, 0.0009514293),\n",
       " (788, 0.00095121044),\n",
       " (380, 0.00095014315),\n",
       " (953, 0.00094959553),\n",
       " (196, 0.00094953383),\n",
       " (866, 0.0009495111),\n",
       " (333, 0.0009462914),\n",
       " (204, 0.0009435934),\n",
       " (801, 0.00094333425),\n",
       " (934, 0.000942503),\n",
       " (939, 0.00094172877),\n",
       " (213, 0.00094128255),\n",
       " (517, 0.00093916844),\n",
       " (390, 0.00093854876),\n",
       " (237, 0.0009381615),\n",
       " (214, 0.0009379555),\n",
       " (331, 0.0009336546),\n",
       " (245, 0.00093245885),\n",
       " (835, 0.0009310142),\n",
       " (170, 0.0009303733),\n",
       " (249, 0.0009303054),\n",
       " (402, 0.0009236168),\n",
       " (445, 0.0009223471),\n",
       " (217, 0.0009213507),\n",
       " (831, 0.0009207695),\n",
       " (180, 0.0009203286),\n",
       " (8, 0.0009186101),\n",
       " (743, 0.0009178228),\n",
       " (938, 0.0009173368),\n",
       " (399, 0.00091719645),\n",
       " (891, 0.0009168112),\n",
       " (230, 0.0009158217),\n",
       " (243, 0.00091152545),\n",
       " (122, 0.0009054369),\n",
       " (246, 0.00090541446),\n",
       " (198, 0.0009013811),\n",
       " (174, 0.00090097956),\n",
       " (639, 0.0009005562),\n",
       " (794, 0.00089819985),\n",
       " (580, 0.0008968068),\n",
       " (579, 0.00089564297),\n",
       " (158, 0.0008928323),\n",
       " (154, 0.00089087395),\n",
       " (482, 0.00088704686),\n",
       " (363, 0.00088672986),\n",
       " (159, 0.0008851094),\n",
       " (721, 0.0008817815),\n",
       " (529, 0.0008796449),\n",
       " (760, 0.00087949),\n",
       " (126, 0.00087797194),\n",
       " (741, 0.0008736591),\n",
       " (94, 0.0008735181),\n",
       " (71, 0.0008665799),\n",
       " (391, 0.0008648273),\n",
       " (200, 0.00086371065),\n",
       " (327, 0.00086269795),\n",
       " (701, 0.000861667),\n",
       " (771, 0.0008614205),\n",
       " (942, 0.0008592811),\n",
       " (357, 0.0008589485),\n",
       " (467, 0.00085741247),\n",
       " (920, 0.0008543491),\n",
       " (809, 0.00085181434),\n",
       " (39, 0.00085151376),\n",
       " (736, 0.00085115276),\n",
       " (757, 0.00084575266),\n",
       " (79, 0.00084438926),\n",
       " (169, 0.0008429999),\n",
       " (671, 0.0008415573),\n",
       " (76, 0.00084091583),\n",
       " (239, 0.00084085733),\n",
       " (164, 0.0008383139),\n",
       " (615, 0.00083449314),\n",
       " (551, 0.0008344639),\n",
       " (441, 0.00083117554),\n",
       " (86, 0.00083070406),\n",
       " (411, 0.00082888),\n",
       " (377, 0.000828065),\n",
       " (960, 0.00082790415),\n",
       " (656, 0.0008275424),\n",
       " (82, 0.00082744926),\n",
       " (844, 0.0008270341),\n",
       " (949, 0.00082610967),\n",
       " (332, 0.0008222153),\n",
       " (524, 0.00082019065),\n",
       " (439, 0.0008188852),\n",
       " (961, 0.00081539014),\n",
       " (480, 0.0008143849),\n",
       " (59, 0.0008131364),\n",
       " (658, 0.0008111948),\n",
       " (563, 0.0008111817),\n",
       " (936, 0.00080969),\n",
       " (854, 0.00080908404),\n",
       " (848, 0.0008086885),\n",
       " (969, 0.00080753025),\n",
       " (337, 0.0008074732),\n",
       " (442, 0.00080669194),\n",
       " (247, 0.0008065856),\n",
       " (657, 0.0008060093),\n",
       " (789, 0.0008046992),\n",
       " (481, 0.00080389366),\n",
       " (670, 0.0008024171),\n",
       " (330, 0.00080228166),\n",
       " (123, 0.00080046884),\n",
       " (150, 0.0008001622),\n",
       " (472, 0.0007998046),\n",
       " (571, 0.0007956751),\n",
       " (931, 0.00078517915),\n",
       " (476, 0.00078415324),\n",
       " (905, 0.00077892566),\n",
       " (665, 0.00077826774),\n",
       " (61, 0.0007758708),\n",
       " (624, 0.00077302504),\n",
       " (981, 0.00077280705),\n",
       " (575, 0.00077241287),\n",
       " (509, 0.0007703621),\n",
       " (221, 0.0007700451),\n",
       " (746, 0.00076957303),\n",
       " (560, 0.00076940336),\n",
       " (679, 0.0007689656),\n",
       " (268, 0.00076765823),\n",
       " (63, 0.00076740753),\n",
       " (241, 0.0007670988),\n",
       " (229, 0.0007654014),\n",
       " (88, 0.0007626974),\n",
       " (893, 0.00076177286),\n",
       " (759, 0.00075844745),\n",
       " (201, 0.00075713685),\n",
       " (735, 0.0007567754),\n",
       " (532, 0.00075190974),\n",
       " (697, 0.0007513987),\n",
       " (423, 0.00074882474),\n",
       " (739, 0.0007486796),\n",
       " (601, 0.0007471235),\n",
       " (988, 0.00074648764),\n",
       " (485, 0.0007442927),\n",
       " (956, 0.00074114656),\n",
       " (688, 0.0007389668),\n",
       " (549, 0.00073656597),\n",
       " (362, 0.00073576206),\n",
       " (422, 0.0007347862),\n",
       " (177, 0.00073118706),\n",
       " (561, 0.0007307907),\n",
       " (17, 0.00072914595),\n",
       " (877, 0.00072829775),\n",
       " (884, 0.00072744564),\n",
       " (18, 0.0007263772),\n",
       " (718, 0.00072293176),\n",
       " (468, 0.0007220762),\n",
       " (454, 0.0007186618),\n",
       " (705, 0.0007182336),\n",
       " (712, 0.00071730505),\n",
       " (768, 0.0007171628),\n",
       " (156, 0.00071544904),\n",
       " (62, 0.0007134892),\n",
       " (651, 0.0007122772),\n",
       " (436, 0.0007082434),\n",
       " (881, 0.0007080119),\n",
       " (702, 0.0007078455),\n",
       " (970, 0.0007053598),\n",
       " (629, 0.0007046229),\n",
       " (262, 0.0007023683),\n",
       " (299, 0.0007019958),\n",
       " (23, 0.000701753),\n",
       " (930, 0.00070138654),\n",
       " (672, 0.0007000236),\n",
       " (634, 0.00069988245),\n",
       " (453, 0.00069670455),\n",
       " (424, 0.0006926843),\n",
       " (951, 0.0006917855),\n",
       " (553, 0.000691306),\n",
       " (526, 0.0006883075),\n",
       " (382, 0.0006877362),\n",
       " (660, 0.0006874483),\n",
       " (958, 0.00068710366),\n",
       " (924, 0.0006865746),\n",
       " (67, 0.0006829784),\n",
       " (602, 0.0006819554),\n",
       " (614, 0.00067725545),\n",
       " (348, 0.00067568006),\n",
       " (378, 0.00067531527),\n",
       " (612, 0.00067496276),\n",
       " (218, 0.0006745303),\n",
       " (145, 0.0006715735),\n",
       " (727, 0.00067108136),\n",
       " (458, 0.00066997716),\n",
       " (944, 0.0006679986),\n",
       " (627, 0.00066764036),\n",
       " (952, 0.00066698773),\n",
       " (858, 0.000665171),\n",
       " (654, 0.0006628076),\n",
       " (945, 0.0006613445),\n",
       " (957, 0.00066133565),\n",
       " (311, 0.00066045026),\n",
       " (607, 0.00065474166),\n",
       " (886, 0.0006514012),\n",
       " (58, 0.0006503669),\n",
       " (44, 0.0006471028),\n",
       " (878, 0.0006470605),\n",
       " (863, 0.00064606895),\n",
       " (630, 0.0006446503),\n",
       " (5, 0.0006403986),\n",
       " (280, 0.0006399985),\n",
       " (292, 0.0006397125),\n",
       " (54, 0.0006377284),\n",
       " (206, 0.00063610903),\n",
       " (416, 0.00063500315),\n",
       " (65, 0.00063484086),\n",
       " (190, 0.0006322213),\n",
       " (96, 0.0006314711),\n",
       " (85, 0.0006291691),\n",
       " (260, 0.00062467385),\n",
       " (52, 0.0006244614),\n",
       " (45, 0.00062315987),\n",
       " (745, 0.0006176447),\n",
       " (906, 0.00061728753),\n",
       " (389, 0.0006168521),\n",
       " (853, 0.00061477075),\n",
       " (990, 0.00061353855),\n",
       " (233, 0.0006129603),\n",
       " (121, 0.0006128931),\n",
       " (496, 0.00061285566),\n",
       " (244, 0.00061193656),\n",
       " (995, 0.00061071647),\n",
       " (581, 0.0006106747),\n",
       " (498, 0.000610047),\n",
       " (751, 0.00060685806),\n",
       " (967, 0.00060529157),\n",
       " (34, 0.0006043766),\n",
       " (334, 0.0006026098),\n",
       " (261, 0.0006018058),\n",
       " (360, 0.00059961533),\n",
       " (590, 0.0005988032),\n",
       " (153, 0.0005975574),\n",
       " (444, 0.0005950191),\n",
       " (972, 0.00059340696),\n",
       " (165, 0.00059184415),\n",
       " (104, 0.00059115794),\n",
       " (43, 0.0005908913),\n",
       " (928, 0.00059084385),\n",
       " (597, 0.00059007294),\n",
       " (175, 0.00058864465),\n",
       " (983, 0.00058585196),\n",
       " (443, 0.00058557536),\n",
       " (474, 0.0005848654),\n",
       " (857, 0.0005847447),\n",
       " (497, 0.0005844181),\n",
       " (864, 0.00058288896),\n",
       " (371, 0.00058236596),\n",
       " (536, 0.00058215373),\n",
       " (1, 0.0005819392),\n",
       " (962, 0.00058170524),\n",
       " (406, 0.00058149535),\n",
       " (815, 0.0005806216),\n",
       " (365, 0.00058011286),\n",
       " (12, 0.00057827093),\n",
       " (887, 0.0005747258),\n",
       " (713, 0.0005721062),\n",
       " (53, 0.0005718981),\n",
       " (486, 0.0005716094),\n",
       " (312, 0.0005714493),\n",
       " (915, 0.0005698192),\n",
       " (50, 0.00056866976),\n",
       " (586, 0.00056613283),\n",
       " (901, 0.0005660234),\n",
       " (93, 0.0005657432),\n",
       " (66, 0.00056517264),\n",
       " (955, 0.0005647391),\n",
       " (166, 0.00056443014),\n",
       " (319, 0.0005643173),\n",
       " (538, 0.00055916555),\n",
       " (867, 0.0005569055),\n",
       " (662, 0.0005558211),\n",
       " (342, 0.0005554539),\n",
       " (340, 0.0005548081),\n",
       " (125, 0.0005546059),\n",
       " (431, 0.00055273843),\n",
       " (374, 0.0005500441),\n",
       " (533, 0.0005498267),\n",
       " (328, 0.0005488684),\n",
       " (77, 0.00054779736),\n",
       " (941, 0.00054595416),\n",
       " (134, 0.000545511),\n",
       " (800, 0.00054496335),\n",
       " (228, 0.0005433175),\n",
       " (309, 0.0005432991),\n",
       " (810, 0.00054011913),\n",
       " (869, 0.0005395983),\n",
       " (430, 0.00053858483),\n",
       " (210, 0.0005354699),\n",
       " (437, 0.0005286019),\n",
       " (940, 0.0005268738),\n",
       " (364, 0.0005261734),\n",
       " (812, 0.000525849),\n",
       " (686, 0.0005233266),\n",
       " (682, 0.00052223186),\n",
       " (119, 0.00052166183),\n",
       " (973, 0.0005216076),\n",
       " (302, 0.0005205292),\n",
       " (609, 0.0005198127),\n",
       " (287, 0.0005194066),\n",
       " (303, 0.00051796506),\n",
       " (394, 0.0005174059),\n",
       " (272, 0.000517067),\n",
       " (698, 0.00051588955),\n",
       " (38, 0.0005138786),\n",
       " (965, 0.00051367196),\n",
       " (732, 0.0005131211),\n",
       " (839, 0.00051302597),\n",
       " (367, 0.00051242375),\n",
       " (370, 0.00051010057),\n",
       " (46, 0.0005098935),\n",
       " (194, 0.00050931895),\n",
       " (555, 0.00050896767),\n",
       " (298, 0.0005083365),\n",
       " (847, 0.0005071887),\n",
       " (99, 0.0005064811),\n",
       " (465, 0.0005062785),\n",
       " (550, 0.00050499215),\n",
       " (569, 0.0005047884),\n",
       " (450, 0.0005047347),\n",
       " (381, 0.000503139),\n",
       " (15, 0.0005019091),\n",
       " (64, 0.0004961104),\n",
       " (984, 0.00049610523),\n",
       " (460, 0.0004926282),\n",
       " (755, 0.0004922971),\n",
       " (89, 0.0004909694),\n",
       " (286, 0.00048961636),\n",
       " (511, 0.00048817042),\n",
       " (894, 0.0004878493),\n",
       " (103, 0.00048592564),\n",
       " (779, 0.00048499982),\n",
       " (724, 0.00048468355),\n",
       " (407, 0.0004830049),\n",
       " (935, 0.0004805526),\n",
       " (117, 0.00047788926),\n",
       " (29, 0.00047652825),\n",
       " (19, 0.00046992645),\n",
       " (16, 0.00046899635),\n",
       " (279, 0.0004686733),\n",
       " (598, 0.0004683468),\n",
       " (47, 0.0004682347),\n",
       " (603, 0.00046756837),\n",
       " (527, 0.00046733613),\n",
       " (315, 0.0004635221),\n",
       " (400, 0.0004611264),\n",
       " (715, 0.0004610541),\n",
       " (565, 0.00046092505),\n",
       " (408, 0.0004609056),\n",
       " (908, 0.00046010883),\n",
       " (829, 0.0004592093),\n",
       " (56, 0.00045908234),\n",
       " (706, 0.00045843897),\n",
       " (729, 0.00045473542),\n",
       " (922, 0.0004541227),\n",
       " (405, 0.00045397916),\n",
       " (252, 0.00045377476),\n",
       " (385, 0.00045324146),\n",
       " (963, 0.00045171368),\n",
       " (595, 0.0004504943),\n",
       " (4, 0.00045014126),\n",
       " (9, 0.00045011594),\n",
       " (111, 0.0004475442),\n",
       " (40, 0.000446987),\n",
       " (269, 0.00044568576),\n",
       " (927, 0.00044424087),\n",
       " (28, 0.0004441232),\n",
       " (353, 0.00044174248),\n",
       " (167, 0.0004381574),\n",
       " (84, 0.00043805104),\n",
       " (410, 0.00043676965),\n",
       " (798, 0.00043527107),\n",
       " (832, 0.00043494866),\n",
       " (35, 0.00043442415),\n",
       " (152, 0.00043394597),\n",
       " (781, 0.0004335398),\n",
       " (2, 0.00043247058),\n",
       " (372, 0.00043192762),\n",
       " (335, 0.000431783),\n",
       " (37, 0.00043159007),\n",
       " (354, 0.00043083588),\n",
       " (73, 0.00043008875),\n",
       " (90, 0.00042264292),\n",
       " (890, 0.00042252676),\n",
       " (69, 0.00042210324),\n",
       " (379, 0.00042143936),\n",
       " (144, 0.00042072858),\n",
       " (980, 0.0004203494),\n",
       " (913, 0.00041918913),\n",
       " (383, 0.00041878666),\n",
       " (645, 0.00041790536),\n",
       " (270, 0.00041789238),\n",
       " (780, 0.00041698353),\n",
       " (997, 0.00041563404),\n",
       " (106, 0.00041389719),\n",
       " (33, 0.00041298027),\n",
       " (717, 0.00041267142),\n",
       " (856, 0.000411589),\n",
       " (288, 0.0004115875),\n",
       " (97, 0.00041017053),\n",
       " (669, 0.00040902637),\n",
       " (25, 0.00040784004),\n",
       " (690, 0.0004062131),\n",
       " (255, 0.00040572355),\n",
       " (83, 0.00040539267),\n",
       " (136, 0.00040341745),\n",
       " (41, 0.00040331588),\n",
       " (68, 0.00040273168),\n",
       " (668, 0.00040047296),\n",
       " (32, 0.0004004292),\n",
       " (985, 0.00040042703),\n",
       " (27, 0.0003991297),\n",
       " (21, 0.00039825955),\n",
       " (959, 0.00039781592),\n",
       " (42, 0.00039673716),\n",
       " (535, 0.00039649624),\n",
       " (271, 0.0003891697),\n",
       " (277, 0.00038811838),\n",
       " (576, 0.00038675495),\n",
       " (346, 0.00038644922),\n",
       " (592, 0.00038599657),\n",
       " (537, 0.00037949134),\n",
       " (11, 0.00037694178),\n",
       " (449, 0.00037468396),\n",
       " (989, 0.000373813),\n",
       " (14, 0.0003702602),\n",
       " (900, 0.00037022473),\n",
       " (675, 0.00036973218),\n",
       " (384, 0.00036853788),\n",
       " (293, 0.00036814605),\n",
       " (101, 0.00036729805),\n",
       " (369, 0.00036416066),\n",
       " (964, 0.0003638925),\n",
       " (540, 0.0003622408),\n",
       " (685, 0.00036091596),\n",
       " (307, 0.00035918094),\n",
       " (102, 0.00035916097),\n",
       " (520, 0.0003584025),\n",
       " (994, 0.0003582694),\n",
       " (694, 0.00035775572),\n",
       " (925, 0.00035491324),\n",
       " (55, 0.00035283825),\n",
       " (814, 0.00035187678),\n",
       " (825, 0.00035163565),\n",
       " (873, 0.00035110093),\n",
       " (6, 0.00034994137),\n",
       " (31, 0.00034934285),\n",
       " (368, 0.00034927146),\n",
       " (525, 0.00034901817),\n",
       " (726, 0.00034833295),\n",
       " (329, 0.0003481966),\n",
       " (276, 0.00034814278),\n",
       " (75, 0.0003453925),\n",
       " (375, 0.00034391606),\n",
       " (13, 0.00034321382),\n",
       " (483, 0.00034270217),\n",
       " (295, 0.00034232126),\n",
       " (648, 0.00034158782),\n",
       " (132, 0.00034077055),\n",
       " (888, 0.0003404872),\n",
       " (991, 0.0003389232),\n",
       " (661, 0.0003384454),\n",
       " (30, 0.00033829693),\n",
       " (895, 0.00033526472),\n",
       " (120, 0.0003351366),\n",
       " (26, 0.00033354736),\n",
       " (625, 0.00033270128),\n",
       " (128, 0.00033136873),\n",
       " (49, 0.0003308979),\n",
       " (397, 0.00033042487),\n",
       " (301, 0.00032916476),\n",
       " (396, 0.00032852136),\n",
       " (146, 0.0003268794),\n",
       " (510, 0.0003267066),\n",
       " (833, 0.00032597507),\n",
       " (321, 0.00032559523),\n",
       " (10, 0.00032544124),\n",
       " (386, 0.00032367252),\n",
       " (425, 0.00032184084),\n",
       " (108, 0.00032045366),\n",
       " (24, 0.00031822754),\n",
       " (821, 0.00031799235),\n",
       " (992, 0.00031660203),\n",
       " (296, 0.00031580625),\n",
       " (343, 0.00031534367),\n",
       " (305, 0.00031028764),\n",
       " (350, 0.00030980443),\n",
       " (105, 0.00030848096),\n",
       " (80, 0.0003074953),\n",
       " (100, 0.00030366034),\n",
       " (946, 0.00030334273),\n",
       " (135, 0.00030240015),\n",
       " (74, 0.00029994038),\n",
       " (129, 0.0002987089),\n",
       " (871, 0.00029810716),\n",
       " (548, 0.00029687956),\n",
       " (564, 0.0002953513),\n",
       " (734, 0.00029361408),\n",
       " (926, 0.0002935634),\n",
       " (339, 0.00029318786),\n",
       " (57, 0.000290803),\n",
       " (817, 0.00029046353),\n",
       " (318, 0.00028896698),\n",
       " (388, 0.00028741173),\n",
       " (689, 0.00028679377),\n",
       " (687, 0.00028671103),\n",
       " (628, 0.00028608585),\n",
       " (326, 0.00028439),\n",
       " (320, 0.0002826905),\n",
       " (116, 0.0002824341),\n",
       " (91, 0.0002814451),\n",
       " (294, 0.00027690353),\n",
       " (290, 0.0002757746),\n",
       " (0, 0.00027461333),\n",
       " (131, 0.00027460282),\n",
       " (278, 0.00027382345),\n",
       " (275, 0.0002723414),\n",
       " (803, 0.000271337),\n",
       " (802, 0.0002713035),\n",
       " (493, 0.0002709986),\n",
       " (48, 0.00026784674),\n",
       " (979, 0.000267754),\n",
       " (376, 0.00026731525),\n",
       " (495, 0.0002669416),\n",
       " (322, 0.00026549376),\n",
       " (274, 0.00026511925),\n",
       " (976, 0.0002607021),\n",
       " (304, 0.00025968743),\n",
       " (127, 0.00025874507),\n",
       " (316, 0.00025773203),\n",
       " (554, 0.00025562113),\n",
       " (137, 0.00025532488),\n",
       " (484, 0.00025383095),\n",
       " (130, 0.00025269692),\n",
       " (291, 0.00025238044),\n",
       " (573, 0.00025222093),\n",
       " (133, 0.0002488567),\n",
       " (324, 0.00024843923),\n",
       " (392, 0.0002481688),\n",
       " (109, 0.0002475429),\n",
       " (148, 0.00024688485),\n",
       " (663, 0.0002461025),\n",
       " (649, 0.00024587288),\n",
       " (3, 0.00024506418),\n",
       " (344, 0.00024504436),\n",
       " (336, 0.00024451944),\n",
       " (387, 0.00024409711),\n",
       " (317, 0.00024330066),\n",
       " (352, 0.00024296915),\n",
       " (466, 0.0002413884),\n",
       " (143, 0.00024126182),\n",
       " (349, 0.00023958254),\n",
       " (22, 0.0002326617),\n",
       " (98, 0.00022794846),\n",
       " (92, 0.00022696354),\n",
       " (20, 0.00022612097),\n",
       " (107, 0.00022272232),\n",
       " (325, 0.00021642902),\n",
       " (300, 0.00021446242),\n",
       " (70, 0.00021243101),\n",
       " (347, 0.0002107023),\n",
       " (366, 0.00020942104),\n",
       " (141, 0.00020852353),\n",
       " (140, 0.00020723743),\n",
       " (297, 0.00020567555),\n",
       " (308, 0.00020479922),\n",
       " (110, 0.00020437846),\n",
       " (323, 0.00020373102),\n",
       " (289, 0.00020364109),\n",
       " (72, 0.00020295552),\n",
       " (149, 0.00019875124),\n",
       " (95, 0.00018927411),\n",
       " (933, 0.00018470835),\n",
       " (820, 0.00018454104),\n",
       " (139, 0.00018359654),\n",
       " (974, 0.00017516619),\n",
       " (640, 0.00017390552),\n",
       " (500, 0.00017241806),\n",
       " (147, 0.00017148757),\n",
       " (81, 0.00017028964),\n",
       " (404, 0.00016770359),\n",
       " (138, 0.00016755596),\n",
       " (115, 0.0001629129),\n",
       " (393, 0.00015564731),\n",
       " (914, 0.00014537398),\n",
       " (874, 0.00013641651),\n",
       " (986, 0.0001357327),\n",
       " (403, 0.00013383343),\n",
       " (142, 0.00012101738),\n",
       " (547, 0.000118899414),\n",
       " (993, 0.000108240354),\n",
       " (351, 0.000106307365)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(enumerate(list(pred_probs))), key=lambda tup: tup[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69316197-bc96-4b4f-88c5-e41fb763d210",
   "metadata": {},
   "outputs": [],
   "source": [
    "io.imsave(data_path / (\"pen.jpg\"), image.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed24dfc4-d01d-40a7-a09a-ba1131a8c320",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc06f43d-c1e4-4f44-b89d-4d933bbee391",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchvision.io.image import read_image\n",
    "from PIL import Image\n",
    "from torchvision.models.segmentation import fcn_resnet50, FCN_ResNet50_Weights\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "img = Image.open(code_dir / \"data\" / 'dog.jpg')\n",
    "\n",
    "# Step 1: Initialize model with the best available weights\n",
    "weights = FCN_ResNet50_Weights.DEFAULT\n",
    "model = fcn_resnet50(weights=weights)\n",
    "model.eval()\n",
    "\n",
    "# Step 2: Initialize the inference transforms\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "# Step 3: Apply inference preprocessing transforms\n",
    "batch = preprocess(img).unsqueeze(0)\n",
    "\n",
    "# Step 4: Use the model and visualize the prediction\n",
    "prediction = model(batch)[\"out\"]\n",
    "normalized_masks = prediction.softmax(dim=1)\n",
    "class_to_idx = {cls: idx for (idx, cls) in enumerate(weights.meta[\"categories\"])}\n",
    "mask = normalized_masks[0, class_to_idx[\"dog\"]]\n",
    "to_pil_image(mask).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67bd80c9-28de-4652-8768-ebb9764323e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__background__',\n",
       " 'aeroplane',\n",
       " 'bicycle',\n",
       " 'bird',\n",
       " 'boat',\n",
       " 'bottle',\n",
       " 'bus',\n",
       " 'car',\n",
       " 'cat',\n",
       " 'chair',\n",
       " 'cow',\n",
       " 'diningtable',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'motorbike',\n",
       " 'person',\n",
       " 'pottedplant',\n",
       " 'sheep',\n",
       " 'sofa',\n",
       " 'train',\n",
       " 'tvmonitor']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.meta[\"categories\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b996710a-16e6-440e-b383-984f0f62ce72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /home/iternal/.cache/torch/hub/v0.10.0.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "# or any of these variants\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43b062c2-30ff-49e7-8366-70a4e4958c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download an example image from the pytorch website\n",
    "import urllib\n",
    "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db5e85c9-178a-487f-9b29-d9c4fc25212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"crop2.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3057930b-918a-462a-94e3-fa96c033cf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample execution (requires torchvision)\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "input_image = Image.open(filename)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "# move the input and model to GPU for speed if available\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "# Tensor of shape 1000, with confidence scores over ImageNet's 1000 classes\n",
    "# print(output[0])\n",
    "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "# print(probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "131eaa7d-8180-4b3e-9022-81bd3c4468d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-13 19:40:07--  https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10472 (10K) [text/plain]\n",
      "Saving to: imagenet_classes.txt\n",
      "\n",
      "imagenet_classes.tx 100%[===================>]  10.23K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-07-13 19:40:07 (39.0 MB/s) - imagenet_classes.txt saved [10472/10472]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download ImageNet labels\n",
    "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f7e92a7-5d0d-4f9a-9bdb-a2321955034d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "washbasin 0.4116014838218689\n",
      "soap dispenser 0.09876617789268494\n",
      "toilet seat 0.06358987838029861\n",
      "bathtub 0.04791147634387016\n",
      "can opener 0.025523997843265533\n"
     ]
    }
   ],
   "source": [
    "# Read the categories\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "# Show top categories per image\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(categories[top5_catid[i]], top5_prob[i].item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
