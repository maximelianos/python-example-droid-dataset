{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92df97c9-d292-42d0-abe5-3e1920b1a8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from skimage.transform import rescale, resize\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea241f08-3b9a-42cb-b4d4-2017b183206e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/last_0072.jpg\n"
     ]
    }
   ],
   "source": [
    "# === Load last image before max\n",
    "data_path = Path(\"data\")\n",
    "file_list = sorted(data_path.glob(\"last_*jpg\"))\n",
    "print(file_list[-1])\n",
    "last_image = io.imread(file_list[-1])\n",
    "\n",
    "imginfo = lambda img: print(type(img), img.dtype, img.shape, img.min(), img.max())\n",
    "\n",
    "first_image = io.imread(\"data/first_image.jpg\")\n",
    "max_image = io.imread(\"data/max_image.jpg\")\n",
    "\n",
    "# === load first touch coors\n",
    "import json\n",
    "with open(\"data/single_log.json\") as f:\n",
    "    episode_log = json.load(f)\n",
    "first_x, first_y, first_z = map(int, episode_log[\"first_touch\"])\n",
    "cropw = 200\n",
    "\n",
    "def to_batch(image):\n",
    "    downscaled = resize(image, (224, 224))\n",
    "    batch = torch.from_numpy(downscaled)[None, :, :, :].to(torch.float32) / 255  # [h, w, c] -> [1, h, w, c]\n",
    "    batch = batch.permute(0, 3, 1, 2)  # [1, h, w, c] -> [1, c, h, w]\n",
    "    return batch\n",
    "\n",
    "def crop(image):\n",
    "    \"\"\"\n",
    "    :param image: [h, w, c]\n",
    "    \"\"\"\n",
    "    return image[first_y-cropw:first_y+cropw, first_x-cropw:first_x+cropw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bd9eadf-eec3-44f2-8e7c-c54221d450c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "img = cv.imread('data/grip_image.jpg')\n",
    "gray = cv.cvtColor(crop(first_image), cv.COLOR_BGR2GRAY)\n",
    " \n",
    "sift = cv.SIFT_create()\n",
    "kp = sift.detect(gray,None)\n",
    " \n",
    "img=cv.drawKeypoints(gray,kp,img)\n",
    " \n",
    "cv.imwrite('sift_keypoints.jpg',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e8cc11-7770-4aa8-aeff-91c2a28dd398",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
